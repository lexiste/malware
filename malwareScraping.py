#!/usr/bin/env python3

##
## concept from @kindredsec
## https://www.youtube.com/watch?v=y5OObEOWuDY&feature=youtu.be
##

import re
import requests
import json
import time
import datetime
import logging
import signal
import wget

blnDebugFlag = False

def debugLogging(strOut):
    stamp = str(datetime.datetime.now()).split(".")[0]
    logging.debug("{0}".format(strOut))
   
def infoLogging(strOut):
    stamp = str(datetime.datetime.now()).split(".")[0]
    logging.info("{0}".format(strOut))

def signal_handler(signal, frame):
    print("\nprogram exiting cleanly")
    raise SystemExit(0)
signal.signal(signal.SIGINT, signal_handler)

## this might work ... ???
def processFile(key, type):
    dlURL = 'https://pastebin.com/raw/' + key
    fileName = PASTEBIN_DOWNLOADS + key + "-" + type + ".txt"
    infoLogging("downloading {0} of {1} from {2}".format(key, type, dlURL))
    #print("downloading {0} of {1}".format(key, type))
    if blnDebugFlag:
      debugLogging("downloading {0}".format(dlURL))
    wget.download(dlURL)

PASTEBIN_DOWNLOADS = "~/pastebins/"

## these are the various patterns we want to watch for
KEY_STRINGS = {'posh':'powershell',
                'posh_script':'Invoke-',
                'posh_webclient':'Net.WebClient',
                'base64_pe':'TVq',
                'base64_gz':'H4sI',
                'py_syscall':'os.system',
                'pl_syscall':'system(',
                'bash':'#!/bin/bash',
                'vba_open':'Auto_Open()',
                'vbs_shell':'wscript.shell'
                }

previousScrape = []

while True:
    parsedKeys = []
    newScrapes = []

    ### Read in last N posts and get the key and put in array
    now = str(datetime.datetime.now()).split(".")[0]
    ## Logging Setup
    logging.basicConfig(filename='malwareScraping.log',level=logging.INFO,format='%(asctime)s %(levelname)-8s %(message)s',datefmt='%Y-%m-%d %H:%M:%S%p')
    infoLogging("starting process")
    post_limit = '100' ## max number of records we can request is 250
    last_n_posts = requests.get('https://scrape.pastebin.com/api_scraping.php?limit=' + post_limit).text
    json_posts = json.loads(last_n_posts)

    for post in json_posts:
        if post['key'] not in previousScrape:
            raw_post_text = requests.get('https://scrape.pastebin.com/api_scrape_item.php?i='+ post['key'])
            if blnDebugFlag:
                debugLogging("checking {0} for keys...".format(post['key']))
            for filetype, fingerprint in KEY_STRINGS.items():
                if fingerprint in raw_post_text.text and post['key'] not in parsedKeys:
                    if blnDebugFlag:
                        debugLogging("found key match in {0}".format(post['key']))
                    now = str(datetime.datetime.now()).split(".")[0]
                    infoLogging("[+] potential file identified, calling download process...")
                    processFile(post['key'], filetype)  ## find the pastebin ID and the type of file from the
                    parsedKeys.append(post['key'])

            newScrapes.append(post['key'])

        previousScrape = newScrapes
        time.sleep(15)
